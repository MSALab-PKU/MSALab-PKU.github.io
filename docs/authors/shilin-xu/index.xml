<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Shilin Xu | Multimedia Semantic Analytics Lab</title>
    <link>https://MSALab-PKU.github.io/authors/shilin-xu/</link>
      <atom:link href="https://MSALab-PKU.github.io/authors/shilin-xu/index.xml" rel="self" type="application/rss+xml" />
    <description>Shilin Xu</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Maintained by MSALab</copyright><lastBuildDate>Tue, 08 Oct 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://MSALab-PKU.github.io/media/icon_hue8824e70fad2ec22483c9a618e12a83f_9721_512x512_fill_lanczos_center_3.png</url>
      <title>Shilin Xu</title>
      <link>https://MSALab-PKU.github.io/authors/shilin-xu/</link>
    </image>
    
    <item>
      <title>RLRF4Rec: Reinforcement Learning from Recsys Feedback for Enhanced Recommendation Reranking</title>
      <link>https://MSALab-PKU.github.io/publication/rlrf4rec-2024/</link>
      <pubDate>Tue, 08 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://MSALab-PKU.github.io/publication/rlrf4rec-2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>LLAVADI: What Matters For Multimodal Large Language Models Distillation</title>
      <link>https://MSALab-PKU.github.io/publication/llavadi-2024/</link>
      <pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://MSALab-PKU.github.io/publication/llavadi-2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards open vocabulary learning: A survey</title>
      <link>https://MSALab-PKU.github.io/publication/towards-2024/</link>
      <pubDate>Mon, 05 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://MSALab-PKU.github.io/publication/towards-2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RAP-SAM: Towards Real-Time All-Purpose Segment Anything</title>
      <link>https://MSALab-PKU.github.io/publication/rap-2024/</link>
      <pubDate>Thu, 18 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://MSALab-PKU.github.io/publication/rap-2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dst-det: Simple dynamic self-training for open-vocabulary object detection</title>
      <link>https://MSALab-PKU.github.io/publication/dst-2024/</link>
      <pubDate>Mon, 02 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://MSALab-PKU.github.io/publication/dst-2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Panopticpartformer&#43;&#43;: A unified and decoupled view for panoptic part segmentation</title>
      <link>https://MSALab-PKU.github.io/publication/panopticpartformer&#43;&#43;-2022/</link>
      <pubDate>Wed, 22 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://MSALab-PKU.github.io/publication/panopticpartformer&#43;&#43;-2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Panoptic-partformer: Learning a unified model for panoptic part segmentation</title>
      <link>https://MSALab-PKU.github.io/publication/partformer-2022/</link>
      <pubDate>Sun, 23 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://MSALab-PKU.github.io/publication/partformer-2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fashionformer: A simple, effective and unified baseline for human fashion segmentation and recognition</title>
      <link>https://MSALab-PKU.github.io/publication/fashionformer-2022/</link>
      <pubDate>Sat, 22 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://MSALab-PKU.github.io/publication/fashionformer-2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Query Learning of Both Thing and Stuff for Panoptic Segmentation</title>
      <link>https://MSALab-PKU.github.io/publication/query-2022/</link>
      <pubDate>Tue, 18 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://MSALab-PKU.github.io/publication/query-2022/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
